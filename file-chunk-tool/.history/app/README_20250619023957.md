# File Chunking Service for Whisper Transcription

This project provides a solution for chunking large files (>25MB) into smaller pieces (<25MB) for processing with OpenAI's Whisper transcription service via n8n workflows.

## Project Structure

```
/app/
  ├─ n8n/                ← your existing n8n service
  └─ fastapi-service/    ← file chunking service
      ├─ main.py         ← FastAPI application
      ├─ requirements.txt ← Python dependencies
      ├─ Dockerfile      ← Docker configuration
      ├─ README.md       ← Service documentation
      ├─ test_client.py  ← Test script for the service
      └─ example_n8n_workflow.json ← Example n8n workflow
```

## Getting Started

### Running with Docker Compose

The easiest way to run both the n8n service and the file chunking service is using Docker Compose:

```bash
cd app
docker-compose up -d
```

This will start:
- n8n on http://localhost:5678
- File Chunking Service on http://localhost:8000

### Running the File Chunking Service Separately

If you want to run just the file chunking service:

```bash
cd app/fastapi-service
docker build -t file-chunker .
docker run -p 8000:8000 file-chunker
```

Or without Docker:

```bash
cd app/fastapi-service
pip install -r requirements.txt
uvicorn main:app --host 0.0.0.0 --port 8000
```

## Testing the File Chunking Service

You can use the included test client to test the file chunking service:

```bash
cd app/fastapi-service
python test_client.py --file /path/to/large/file.mp3
```

This will upload the file to the service and display information about the chunks.

## Integrating with n8n

1. Import the example workflow from `app/fastapi-service/example_n8n_workflow.json` into your n8n instance
2. Update the file paths and API keys in the workflow
3. Activate and run the workflow

The workflow will:
1. Read a large audio file
2. Send it to the File Chunker service
3. Split the file into chunks if necessary
4. Send each chunk to Whisper for transcription
5. Combine the transcriptions
6. Save the result to a file

## API Documentation

When the FastAPI service is running, you can access the API documentation at:
- http://localhost:8000/docs (Swagger UI)
- http://localhost:8000/redoc (ReDoc)

## Key Features

- Automatically chunks files larger than 25MB into smaller pieces
- Stores original files and chunks for later retrieval
- Provides detailed information about chunks for processing
- Includes a test client for easy testing
- Includes an example n8n workflow for integration
- Docker and Docker Compose support for easy deployment

## Notes

- The chunking service creates two directories:
  - `uploads/` for storing original uploaded files
  - `chunks/` for storing chunked files
- These directories are mounted as volumes in the Docker setup to persist data